<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Human Tracking with Audio</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-image: url('home4.png'); /* Background image */
            background-size: cover;
            background-repeat: no-repeat;
            overflow-x: hidden;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
        }

        #videoContainer {
            position: relative;
            width: 100%;
            max-width: 100%;
            background-color: rgba(0, 0, 0, 0.5); /* Transparent background for video */
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        #videoCanvas {
            width: 100%;
            height: auto;
             transform: scaleX(1); /* Flip horizontally */
        }

        #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: auto;
        }

        #box {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 10%;
            height: 50%;
            border: 2px solid #fff;
            cursor: pointer;
            touch-action: none;
            border-radius: 10px;
            z-index: 1;
            transition: border-color 0.3s ease;
        }

        #box:hover {
            border-color: #ff6347;
        }

        #motionText {
            position: absolute;
            top: 100px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 16px;
            color: #fff;
            font-weight: bold;
            opacity: 0;
            transition: opacity 0.3s ease;
        }

        #audioControl {
            position: absolute;
            top: 10px;
            right: 10px;
            font-size: 18px;
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        #audioControl:hover {
            background-color: #45a049;
        }

        #bottomBar {
            margin-top: 20px;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #bottomBar button {
            background-color: #333;
            border: none;
            color: white;
            font-size: 18px;
            font-weight: bold;
            padding: 15px 25px;
            margin: 0 10px;
            cursor: pointer;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        #bottomBar button:hover {
            background-color: #555;
        }
    </style>
</head>
<body>
    <div id="videoContainer">
        <video id="videoCanvas" autoplay playsinline aspectRatio="16:9"></video>
        <canvas id="overlayCanvas"></canvas>
    </div>
    <div id="box"></div>
    <div id="motionText">No Motion Detected</div>
    <button id="audioControl">Toggle Sound</button>

    <div id="bottomBar">
        <button onclick="goToHome()">Home</button>
        <button  onclick="goHelp()">Help</button>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script>
        let soundOn = false;
        let beep = new Audio('beep.mp3');
        beep.loop = true;
        beep.volume = 0.5;

        async function run() {
            const video = document.getElementById('videoCanvas');
            const overlayCanvas = document.getElementById('overlayCanvas');
            const ctx = overlayCanvas.getContext('2d');
            const box = document.getElementById('box');
            const motionText = document.getElementById('motionText');
            const audioControl = document.getElementById('audioControl');

            const model = await cocoSsd.load();
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                        const aspectRatio = video.videoWidth / video.videoHeight;
                        overlayCanvas.width = video.clientWidth;
                        overlayCanvas.height = video.clientWidth / aspectRatio;
                        detectAndDraw(model, video, ctx, box, motionText);
                    };
                })
                .catch(error => {
                    console.error('Error accessing the camera:', error);
                });

            audioControl.addEventListener('click', () => {
                soundOn = !soundOn;
                if (soundOn) {
                    beep.volume = 1;
                    beep.play();
                    audioControl.textContent = 'Sound: On';
                } else {
                    beep.pause();
                    audioControl.textContent = 'Sound: Off';
                }
            });

            // Make the box movable
            let isDragging = false;
            let offsetX, offsetY;

            box.addEventListener('mousedown', startDrag);
            box.addEventListener('touchstart', startDrag);

            function startDrag(e) {
                if (e.type === 'mousedown' && e.buttons === 1 || e.type === 'touchstart') { // Only allow drag on left-click or touch
                    e.preventDefault();
                    isDragging = true;
                    const rect = box.getBoundingClientRect();
                    const parentRect = box.parentElement.getBoundingClientRect();
                    offsetX = (e.clientX || e.touches[0].clientX) - rect.left + parentRect.left;
                    offsetY = (e.clientY || e.touches[0].clientY) - rect.top + parentRect.top;
                    window.addEventListener('mousemove', drag);
                    window.addEventListener('touchmove', drag);
                    window.addEventListener('mouseup', stopDrag);
                    window.addEventListener('touchend', stopDrag);
                }
            }

            function drag(e) {
                if (isDragging) {
                    e.preventDefault();
                    const x = e.clientX || e.touches[0].clientX;
                    const y = e.clientY || e.touches[0].clientY;
                    box.style.left = `${x - offsetX}px`;
                    box.style.top = `${y - offsetY}px`;
                }
            }

            function stopDrag() {
                isDragging = false;
                window.removeEventListener('mousemove', drag);
                window.removeEventListener('touchmove', drag);
                window.removeEventListener('mouseup', stopDrag);
                window.removeEventListener('touchend', stopDrag);
            }
        }

        async function detectAndDraw(model, video, ctx, box, motionText) {
            const predictions = await model.detect(video);
            const widthScale = video.clientWidth / video.videoWidth;
            const heightScale = video.clientHeight / video.videoHeight;

            ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            let motionDetected = false;

            predictions.forEach(prediction => {
                if (prediction.class === 'person') {
                    const [x, y, width, height] = prediction.bbox;
                    const scaledX = x * widthScale;
                    const scaledY = y * heightScale;
                    const scaledWidth = width * widthScale;
                    const scaledHeight = height * heightScale;

                    ctx.beginPath();
                    ctx.lineWidth = '4';
                    ctx.strokeStyle = 'red';
                    ctx.rect(scaledX, scaledY, scaledWidth, scaledHeight);
                    ctx.stroke();

                    const boxRect = box.getBoundingClientRect();
                    const parentRect = box.parentElement.getBoundingClientRect();
                    const boxPosition = {
                        left: boxRect.left - parentRect.left,
                        top: boxRect.top - parentRect.top,
                        right: boxRect.right - parentRect.left,
                        bottom: boxRect.bottom - parentRect.top
                    };

                    if (isIntersect(boxPosition, { left: scaledX, top: scaledY, right: scaledX + scaledWidth, bottom: scaledY + scaledHeight })) {
                        motionDetected = true;
                    }
                }
            });

            if (!motionDetected) {
                motionText.textContent = 'Motion Detected ';
                motionText.style.opacity = '0';
                beep.play();
            } else {
                motionText.textContent = 'No Motion Detected';
                motionText.style.opacity = '1';
                beep.pause();
            }

            requestAnimationFrame(() => detectAndDraw(model, video, ctx, box, motionText));
        }

        function isIntersect(rect1, rect2) {
            return !(rect1.right < rect2.left ||
                rect1.left > rect2.right ||
                rect1.bottom < rect2.top ||
                rect1.top > rect2.bottom);
        }

        function goToHome() {
            window.location.href = "index.html";
        }

        function goHelp() {
            window.location.href = "help.html";
        }

        run();
    </script>
</body>
</html>
